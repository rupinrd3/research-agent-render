# Quick Guide for Users

Welcome! This app is an **Agentic AI Researcher**: it plans, searches the web, reads sources, and writes a report for you. If you've used ChatGPT, this feels familiar—except the agent runs multiple steps and tools automatically.

## Purpose
- For **AI Developers & Risk Managers**: learn the mechanics of Agentic AI solutions — how Traces capture reasoning, how objective vs. LLM-as-judge Evals behave, and whether the signals are reliable.
- For **YOU**: see the inner workings of agentic AI through the workflow animation and Traces while getting a concise research report.

## How it works
- You give a question or topic.
- The agent creates a plan, searches the web, reads pages, and summarizes evidence.
- It iterates until it has enough signal, then produces a structured report.

## What you see on the page
- **Traces**: A live log of the agent’s reasoning and actions (plans, searches, tool calls). Skim to see *why* it chose each step.
- **Research Output**: The final report—read this first. It includes findings, citations, and recommendations.
- **Evals / Quality Check**: A post-run self-review. It flags gaps or risks so you know how trustworthy the output is.
- **Metrics**: Tokens, cost, duration, and provider notes—helpful if you care about spend or performance.

## How to use it
1) Enter a clear question (e.g., “Compare Claude Opus 4.5 vs Gemini 3 Pro for coding teams”).
2) Let the agent run; watch Traces if you’re curious.
3) Read the **Research Output**; check citations.
4) Glance at **Evals** for any warnings.
5) If needed, rerun with a narrower query or ask for a follow-up.

## Tips
- Provide specifics (model names, dates, constraints) for better searches.
- If sources look thin, rerun with more precise wording or a smaller scope.
- Traces are your transparency window—use them to judge credibility.
